# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

---

## Project Overview

**Pilates Class Planner v2.0** - An intelligent Pilates class planning application that combines domain expertise, AI agents, and web research capabilities to create safe, effective, and personalized Pilates classes.

## üéØ DUAL PROJECT GOALS (CRITICAL - READ FIRST)

**This project serves TWO equally important strategic objectives:**

### Goal 1: Build Production-Ready Pilates Platform
- **Objective**: Launch functional MVP to community for customer traction
- **Approach**: Working production code that users can actually use
- **Timeline**: Production-ready now, deploy immediately
- **Quality Standard**: Real features, real integration, real value

### Goal 2: Learn Jentic Architecture Through Implementation
- **Objective**: Deep understanding of Jentic's StandardAgent + Arazzo Engine
- **Context**: Jentic is a CLIENT of Bassline (requires intimate codebase knowledge)
- **Approach**: Learn by doing - integrate real Jentic code, not stubs
- **Timeline**: Parallel with production - learning while building

**CRITICAL DECISION POINT:**
- ‚ùå **NOT** "learn first, then build later"
- ‚ùå **NOT** "build first, refactor later"
- ‚úÖ **YES** "build AND learn simultaneously using real Jentic code"

**WHY BOTH MATTER:**
1. **Customer Traction** requires working production code
2. **Client Relationship** requires deep understanding of Jentic's architecture
3. **Future Projects** require scalable AI infrastructure patterns
4. **Best Learning** happens through real implementation, not theory

**IMPLEMENTATION STRATEGY:**
- Use real Jentic libraries from GitHub (not stubs, not placeholders)
- Heavy educational annotations throughout code ("JENTIC PATTERN" vs "BASSLINE CUSTOM")
- Production quality while learning architecture patterns
- Deploy fully functional integration
- **üéØ CRITICAL: Standardize code using Jentic patterns for maximum scalability**
  - Leverage StandardAgent and Arazzo Engine to their fullest potential
  - Standardized code = easily scalable code
  - Replace custom implementations with Jentic patterns wherever possible
  - Document all deviations from Jentic standards with clear justification

**When making architectural decisions, ALWAYS consider both goals equally.**

---

**Core Architecture:**
- FastAPI backend with AI agents
- React frontend (pixel-perfect copy of existing MVP)
- Supabase PostgreSQL database
- MCP Playwright server for web research
- **Jentic StandardAgent + Arazzo Engine** (integrated from GitHub)
- Four specialized AI agents (sequence, music, meditation, research)

**Design Philosophy:**
- Copy the existing MVP exactly (no improvements, no modernization)
- Safety-first approach with strict sequencing rules
- Database-driven business logic
- EU AI Act and GDPR compliant from day 1
- PII tokenization for all user data
- **Production-ready code with educational annotations** (dual goals)

**Design Plan Source of Truth:**
- **`/Pilates_App_Daily_Sessions_FINAL.md`** is the central source of truth for the development plan
- This file in the MVP2 folder defines all sessions, features, and implementation approach
- Consult it for session-by-session guidance, features roadmap, and architectural decisions
- When planning future work or understanding project scope, refer to this document first

---

## üö® CRITICAL SECURITY RULES üö®

### NEVER Expose Secrets in Code or Documentation

**ABSOLUTE PROHIBITIONS:**

1. **NEVER commit files containing secrets to git**
   - API keys, tokens, passwords, database credentials
   - Supabase keys, JWT secrets, service role keys
   - Any authentication credentials or private keys

2. **NEVER include secrets in documentation files**
   - README.md, deployment docs, or any markdown files
   - Comments in code (even if commented out)
   - Example configurations with real credentials

3. **NEVER put secrets in frontend code**
   - Frontend code is publicly accessible in browser
   - Use environment variables with VITE_ prefix ONLY for public data
   - Backend URLs are OK, but NOT API keys

4. **Files that commonly contain secrets (CHECK BEFORE COMMITTING):**
   - `.env` files (should ALWAYS be in .gitignore)
   - `credentials.json`, `secrets.json`, `config.json`
   - Any file named with "key", "token", "secret", "password"
   - Database connection files, API configuration files
   - Documentation files in `/docs`, `/database`, `/config`

5. **If secrets are exposed:**
   - Immediately rotate/revoke the exposed credentials
   - Remove from git history (git filter-branch or BFG Repo-Cleaner)
   - Add file pattern to .gitignore
   - Verify the secret is not in any other files

6. **Where secrets SHOULD be stored:**
   - Environment variables (`.env` files in .gitignore)
   - Deployment platform environment variables (Render, Netlify)
   - Secret management services (never in code)
   - Local files explicitly listed in .gitignore

7. **Before committing, ALWAYS check:**
   ```bash
   git diff
   git status
   grep -r "eyJ" .  # Check for JWT tokens
   grep -r "sk_" .  # Check for secret keys
   grep -r "password" .  # Check for passwords
   ```

**This is a zero-tolerance policy. A single exposed secret can compromise the entire application.**

---

## üîÑ GIT WORKFLOW POLICY

### Automatic Commits After Code Changes

**RULE:** After making any code changes, automatically commit and push to GitHub unless the user explicitly says not to.

**Process:**
1. Make code changes as requested
2. Stage all modified files: `git add .`
3. Create descriptive commit message with:
   - Summary of changes
   - Files modified
   - Purpose/reason for changes
   - Co-authored-by Claude tag
4. Push to GitHub: `git push origin main`
5. Confirm with user that changes are live

**When NOT to commit:**
- User explicitly says "don't commit" or "wait to commit"
- Files contain secrets or credentials (check first!)
- Changes are experimental/incomplete
- User says they want to review changes first

**Commit Message Format:**
```
<Type>: <Brief summary>

<Detailed description of changes>
<Files modified>
<Purpose/impact>

ü§ñ Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>
```

**Always verify before committing:**
- No secrets exposed (API keys, tokens, passwords)
- No `.env` files being committed
- Changes align with user's request
- All files staged are intentional

---

## Multi-Agent Development Workflow

**IMPORTANT: Use parallel test agents proactively for complex debugging, testing, and validation tasks.**

### When to Use Multi-Agent Workflows

Always launch multiple agents in parallel when:

1. **Debugging Complex Issues**
   - Test API endpoint + Check browser console + Verify database state
   - Inspect frontend state + Check backend logs + Validate data flow

2. **Testing After Changes**
   - Test API response + Verify frontend rendering + Check database integrity
   - Run unit tests + Integration tests + E2E tests

3. **Validating Implementations**
   - Check code structure + Test functionality + Verify compliance
   - Review security + Test performance + Validate UX

4. **Research and Analysis**
   - Search codebase + Read documentation + Test implementation
   - Compare versions + Analyze patterns + Verify consistency

### How to Launch Parallel Agents

**Single message with multiple Task tool calls:**

```typescript
// Launch 3 agents in parallel to debug movement loading issue
Task(subagent_type: "general-purpose", description: "Test movements API endpoint")
Task(subagent_type: "general-purpose", description: "Check browser console logs")
Task(subagent_type: "general-purpose", description: "Verify Zustand store structure")
```

**Example from Session 5 (Movement Loading Bug):**

When movements weren't loading, I launched 3 parallel agents:
1. **API Test Agent** - Verified `/api/movements` returned data correctly
2. **Console Log Agent** - Checked browser console for JavaScript errors
3. **Store Verification Agent** - Compared API response vs Zustand interface

This revealed:
- API was working ‚úì
- CORS was blocking requests ‚úó (root cause found!)
- API Pydantic model missing fields ‚úó (secondary issue)

### Best Practices

1. **Launch agents early** - Don't wait until stuck; use proactively
2. **Run in parallel** - Single message with multiple Task calls
3. **Clear descriptions** - Each agent needs specific, focused task
4. **Trust agent outputs** - Agents have deep context and expertise
5. **Combine findings** - Synthesize multi-agent results for solution

### Example Scenarios

**Scenario 1: New Feature Not Working**
```
Agent 1: Test the API endpoint for the new feature
Agent 2: Verify frontend component receives and renders data
Agent 3: Check database for expected records
Agent 4: Validate user permissions and auth flow
```

**Scenario 2: Performance Issue**
```
Agent 1: Profile backend API response times
Agent 2: Analyze frontend bundle size and load times
Agent 3: Check database query performance
Agent 4: Review caching strategy effectiveness
```

**Scenario 3: CORS/Network Issue**
```
Agent 1: Test API directly with curl
Agent 2: Check browser Network tab for failed requests
Agent 3: Verify CORS configuration in backend
Agent 4: Validate axios configuration in frontend
```

### User Request: "Thoroughly test using parallel test agents"

When the user requests thorough testing with parallel agents:
1. Identify all components that need testing
2. Launch 3-5 agents in a single message
3. Each agent tests one specific aspect
4. Combine results to provide comprehensive diagnosis
5. Present findings and recommended fixes

**Never test serially when parallel is possible** - it saves time and provides faster, more comprehensive results.

---

## Development Commands

### Backend (FastAPI)

```bash
# Install dependencies
cd backend
pip install -r requirements.txt

# Run development server
uvicorn api.main:app --reload --port 8000

# Run tests
pytest tests/ -v

# Run single test
pytest tests/test_sequences.py::test_validate_sequence -v

# Database migrations
alembic upgrade head
alembic revision --autogenerate -m "description"

# Start MCP Playwright server (in separate terminal)
npx @modelcontextprotocol/server-playwright
```

### Frontend (React)

```bash
# Install dependencies
cd frontend
npm install

# Run development server
npm run dev

# Run tests
npm test

# Run single test file
npm test -- ClassBuilder.test.tsx

# Build for production
npm run build

# Type checking
npm run type-check

# Linting
npm run lint
```

### Database (Supabase)

```bash
# Apply migrations
cd database
supabase db push

# Reset database (development only)
supabase db reset

# Generate types
supabase gen types typescript --local > ../frontend/src/types/supabase.ts

# Run SQL function tests
supabase test db
```

### Docker (Full Stack)

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop all services
docker-compose down

# Rebuild after dependencies change
docker-compose up -d --build
```

---

## Architecture Overview

### Backend Structure (`/backend`)

```
backend/
‚îú‚îÄ‚îÄ api/                    # FastAPI routes and endpoints
‚îÇ   ‚îú‚îÄ‚îÄ main.py            # Application entry point
‚îÇ   ‚îú‚îÄ‚îÄ auth.py            # Authentication endpoints
‚îÇ   ‚îú‚îÄ‚îÄ classes.py         # Class planning endpoints
‚îÇ   ‚îú‚îÄ‚îÄ movements.py       # Movement CRUD endpoints
‚îÇ   ‚îî‚îÄ‚îÄ users.py           # User management endpoints
‚îú‚îÄ‚îÄ agents/                 # AI agent implementations
‚îÇ   ‚îú‚îÄ‚îÄ base_agent.py      # Base agent class with EU AI Act compliance
‚îÇ   ‚îú‚îÄ‚îÄ sequence_agent.py  # Movement sequencing logic
‚îÇ   ‚îú‚îÄ‚îÄ music_agent.py     # Music recommendation logic
‚îÇ   ‚îú‚îÄ‚îÄ meditation_agent.py # Meditation script generation
‚îÇ   ‚îî‚îÄ‚îÄ research_agent.py  # MCP Playwright integration
‚îú‚îÄ‚îÄ models/                 # Pydantic models and schemas
‚îÇ   ‚îú‚îÄ‚îÄ movement.py        # Movement data models
‚îÇ   ‚îú‚îÄ‚îÄ class_plan.py      # Class plan schemas
‚îÇ   ‚îú‚îÄ‚îÄ user.py            # User models with PII tokenization
‚îÇ   ‚îî‚îÄ‚îÄ sequence_rule.py   # Sequencing validation models
‚îú‚îÄ‚îÄ services/               # Business logic layer
‚îÇ   ‚îú‚îÄ‚îÄ sequencing.py      # Sequence validation and generation
‚îÇ   ‚îú‚îÄ‚îÄ muscle_balance.py  # Muscle group balance tracking
‚îÇ   ‚îú‚îÄ‚îÄ mcp_client.py      # MCP Playwright client wrapper
‚îÇ   ‚îú‚îÄ‚îÄ excel_sync.py      # Excel database synchronization
‚îÇ   ‚îî‚îÄ‚îÄ safety_validator.py # Safety rule enforcement
‚îî‚îÄ‚îÄ utils/                  # Shared utilities
    ‚îú‚îÄ‚îÄ supabase_client.py # Database connection
    ‚îú‚îÄ‚îÄ pii_tokenizer.py   # PII encryption/tokenization
    ‚îú‚îÄ‚îÄ compliance.py      # EU AI Act logging and monitoring
    ‚îî‚îÄ‚îÄ cache.py           # Redis caching layer
```

### Frontend Structure (`/frontend`)

```
frontend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ components/        # React components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ClassBuilder/  # Main drag-and-drop interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MovementCard/  # Individual movement display
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SequenceViewer/ # Timeline view of class
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ResearchPanel/ # MCP research results display
‚îÇ   ‚îú‚îÄ‚îÄ pages/             # Page-level components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dashboard.tsx  # User dashboard
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ClassPlanner.tsx # Main class planning interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Login.tsx      # Authentication
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Analytics.tsx  # Progress tracking
‚îÇ   ‚îú‚îÄ‚îÄ hooks/             # Custom React hooks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useAuth.ts     # Authentication state
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useClassBuilder.ts # Class planning state
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useMovements.ts # Movement data fetching
‚îÇ   ‚îú‚îÄ‚îÄ services/          # API clients
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.ts         # Axios instance configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classService.ts # Class planning API calls
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ authService.ts # Authentication API calls
‚îÇ   ‚îî‚îÄ‚îÄ utils/             # Frontend utilities
‚îÇ       ‚îú‚îÄ‚îÄ sequenceValidation.ts # Client-side validation
‚îÇ       ‚îî‚îÄ‚îÄ formatters.ts  # Data formatting helpers
```

### Database Structure (`/database`)

The database is Supabase PostgreSQL with the following key tables:

**Core Tables:**
- `movement_details` - All Pilates movements (migrated from Excel)
- `movement_muscles` - Many-to-many muscle group mappings
- `sequence_rules` - Safety and quality sequencing rules
- `class_plans` - Saved class plans
- `user_preferences` - User settings and preferences

**Compliance Tables:**
- `users` - User accounts (PII tokenized)
- `pii_tokens` - Secure PII storage
- `ai_decision_log` - EU AI Act compliance logging
- `bias_monitoring` - Model drift detection

**Functions:**
- `validate_sequence()` - Server-side sequence validation
- `calculate_muscle_balance()` - Track muscle group load
- `get_recommended_movements()` - AI-powered recommendations
- `tokenize_pii()` / `detokenize_pii()` - PII handling

---

## Key Domain Knowledge

### The 34 Classical Pilates Movements

The application is built around Joseph Pilates' 34 classical mat movements, organized by difficulty:

**Beginner (14 movements):** The Hundred, Roll Up, Roll Over, Single Leg Circle, Rolling Like a Ball, Single Leg Stretch, Double Leg Stretch, Spine Stretch Forward, Open Leg Rocker, Corkscrew, The Saw, Swan Dive, Single Leg Kick, Double Leg Kick

**Intermediate (10 movements):** Neck Pull, Scissors, Bicycle, Shoulder Bridge, Spine Twist, Jack Knife, Side Kick Series (Front/Back, Up/Down, Circles), Teaser

**Advanced (10 movements):** Hip Twist, Swimming, Leg Pull Front, Leg Pull Back, Side Bend, Boomerang, Seal, Control Balance, Push Up, Rocking

### Critical Sequencing Rules (Never Violate)

These rules prevent injury and ensure class effectiveness:

1. **Warm-up first** - Always start with breathing and gentle movements
2. **Spinal progression** - Flexion before extension (anatomical safety)
3. **Balance muscle groups** - Don't overwork one area
4. **Complexity progression** - Simple to complex within session
5. **Cool-down required** - End with stretching and breathing

The backend enforces these rules via `services/safety_validator.py` and database function `validate_sequence()`. Any sequence violating these rules will be rejected with a specific error message.

### Movement Attributes (from Excel Database)

Each movement has:
- **Name** - Official classical name
- **Difficulty** - Beginner/Intermediate/Advanced
- **Primary Muscles** - Core, Legs, Arms, Back, etc.
- **Movement Pattern** - Flexion, Extension, Rotation, Lateral, Balance
- **Duration** - Typical time in seconds
- **Breathing Pattern** - Inhale/Exhale counts
- **Prerequisites** - What movements should come before
- **Contraindications** - When to avoid (pregnancy, injuries, etc.)
- **Setup Instructions** - Positioning details
- **Execution Notes** - Step-by-step guidance
- **Modifications** - Easier/harder variations

This data is migrated from `Pilates_Summary_Spreadsheet_teachingTracker_v10.xlsm` into the PostgreSQL database.

---

## AI Agent Architecture

### ‚ö†Ô∏è MIGRATION COMPLETE (December 3, 2025): Jentic StandardAgent

**Old Architecture (Archived):** 4 custom agents in `backend/agents/`
**New Architecture:** ONE StandardAgent + 4 Tool Modules in `orchestrator/agent/tools/`

All business logic has been **preserved and extracted** to tool modules for maximum scalability.

### Current Architecture (Jentic StandardAgent)

```
Backend API (FastAPI)
  ‚Üì HTTP
Orchestrator Service (FastAPI on Render)
  ‚Üì
BasslinePilatesCoachAgent (Jentic StandardAgent)
  ‚Üì Plan ‚Üí Execute ‚Üí Reflect
Tool Modules (Pure Business Logic):
  - SequenceTools (sequencing, muscle balance, safety)
  - MusicTools (playlist generation, BPM matching)
  - MeditationTools (meditation scripts, breathing)
  - ResearchTools (MCP Playwright web research)
```

**Key Benefits:**
- ‚úÖ **Single Agent** - Simpler, easier to maintain
- ‚úÖ **Jentic Patterns** - Industry-standard reasoning (Plan‚ÜíExecute‚ÜíReflect)
- ‚úÖ **Scalability** - Standardized code = easily scalable
- ‚úÖ **Separation** - Agent reasoning separate from domain logic
- ‚úÖ **All Business Logic Preserved** - Nothing lost in migration

### Tool Module Responsibilities

**SequenceTools** (`orchestrator/agent/tools/sequence_tools.py`)
- Validates movement sequences against safety rules
- Generates variations on existing sequences
- Balances muscle groups across class duration
- Ensures appropriate progression of difficulty
- **Extracted from:** `backend/agents/sequence_agent.py` (963 lines)

**MusicTools** (`orchestrator/agent/tools/music_tools.py`)
- Recommends music based on class energy curve
- Matches BPM to movement rhythm
- Considers user preferences and history
- Provides fallback playlists when unavailable
- **Extracted from:** `backend/agents/music_agent.py` (213 lines)

**MeditationTools** (`orchestrator/agent/tools/meditation_tools.py`)
- Generates cool-down meditation scripts
- Adapts to class intensity and duration
- Includes breathing guidance
- Provides theme variety (mindfulness, body scan, gratitude)
- **Extracted from:** `backend/agents/meditation_agent.py` (217 lines)

**ResearchTools** (`orchestrator/agent/tools/research_tools.py`)
- Uses MCP Playwright to search web for Pilates content
- Enhances movement cues from reputable sources
- Finds condition-specific modifications
- Attributes sources for transparency
- **Extracted from:** `backend/agents/research_agent.py` (190 lines)

### Archived Agents

Original backend agents archived in `backend/agents_archive/` (gitignored).
See `/backend/agents_archive/README.md` for migration details.

---

## MCP Playwright Integration

### Setup

The MCP Playwright server runs as a separate process:

```bash
npx @modelcontextprotocol/server-playwright
```

Configuration is in `config/mcp_config.yaml`:

```yaml
mcp_servers:
  playwright:
    command: "npx"
    args: ["@modelcontextprotocol/server-playwright"]
    capabilities:
      - web_navigation
      - screenshot_capture
      - content_extraction
      - form_interaction
    rate_limits:
      requests_per_minute: 30
      concurrent_sessions: 3
```

### Usage in Code

```python
from services.mcp_client import MCPClient

mcp = MCPClient()

# Search for movement cues
cues = await mcp.research_movement_cues(
    movement_name="The Hundred",
    trusted_sites=["pilatesmethod.com", "balancedbody.com"]
)

# Find warm-up exercises
warmups = await mcp.find_warmup_sequence(
    target_muscles=["core", "hip_flexors"],
    duration=5
)

# Research condition-specific modifications
mods = await mcp.research_modifications(
    condition="pregnancy",
    trimester=2
)
```

All MCP results are cached in Redis with source attribution for EU AI Act compliance.

---

## Music Integration (Musopen/FreePD)

### Architecture Decision (Session 10)

**Status:** Planning phase - Implementation scheduled for Session 10

**Strategy:** Royalty-free classical music from Musopen and FreePD
- No per-user OAuth required
- No arbitrary user caps (unlike SoundCloud's 25-user dev limit)
- Royalty-free/public domain music suitable for Pilates
- Streamed from third-party CDN (not self-hosted)
- No ads during playback
- Scalable to unlimited users

### Musical Stylistic Periods

Users select from classical music periods appropriate for Pilates:
- **Baroque Period (c. 1600‚Äì1750)** - Bach, Handel, Vivaldi
- **Classical Period (c. 1750‚Äì1820)** - Mozart, Haydn, early Beethoven
- **Romantic Period (c. 1820‚Äì1910)** - Chopin, Tchaikovsky, Brahms
- **Impressionist Period (c. 1890‚Äì1920)** - Debussy, Ravel
- **Modern Period (c. 1900‚Äì1975)** - Stravinsky, Bart√≥k, Copland
- **Contemporary/Postmodern (1975‚Äìpresent)** - Minimalist, ambient, neo-classical
- **Celtic Traditional**

### Additional Internet Archive Music Sources

**Many more royalty-free classical music tracks available from Internet Archive:**

1. **Musopen DVD Collection** (extensive classical music archive)
   - https://ia802809.us.archive.org/view_archive.php?archive=/20/items/musopen-dvd/Musopen-DVD.zip
   - Comprehensive collection of public domain performances
   - High-quality recordings suitable for Pilates classes

2. **Classical Music Mix by Various Artists**
   - https://archive.org/details/classical-music-mix-by-various-artists/
   - Curated collection spanning multiple periods
   - Easy to browse and download individual tracks

3. **G√©nies du Classique (Vivaldi, Bach, Mozart, Beethoven)**
   - https://archive.org/details/geniesduclassique_vol1no03/01+Vivaldi_+La+Primavera%2C+Concerto+No.1+In+Mi+Maggiore+-+Allegro.wav
   - High-quality WAV files
   - Well-known classical pieces ideal for Pilates

**Usage Notes:**
- All tracks are public domain or Creative Commons licensed
- Can be added to database using same SQL pattern as current tracks
- Remember to add `archive.org` to ALLOWED_STREAMING_DOMAINS whitelist in backend
- Verify audio quality and BPM suitability before adding to playlists

### Database Schema (Planned)

**Core Tables:**
- `music_tracks` - Individual tracks from Musopen/FreePD
  - source (MUSOPEN, FREEPD)
  - title, composer, performer
  - duration_seconds, bpm, stylistic_period
  - audio_url (streaming URL)
  - license_info (CC0, PD, etc.)

- `music_playlists` - Curated playlists by period/intensity
  - name, description
  - intended_intensity (LOW, MEDIUM, HIGH)
  - intended_use (PILATES_SLOW_FLOW, PILATES_CORE, etc.)
  - stylistic_period

- `music_playlist_tracks` - Many-to-many relationship
  - playlist_id, track_id
  - sequence_order

### Vendor-Agnostic Music Source Layer

**Abstract Interface:**
```python
class MusicSource:
    def get_playlists(self, period: str, intensity: str) -> List[Playlist]
    def get_tracks(self, playlist_id: str) -> List[Track]
    def get_streaming_url(self, track_id: str) -> str
```

**Implementations:**
- `MusopenSource` - Primary source (public domain classical)
- `FreePDSource` - Secondary source (CC0 library)
- Future: `JamendoSource`, `EpidemicSource` (when budget allows)

### Security Considerations

- Never expose provider API keys to client
- Validate and whitelist audio streaming domains
- No "open proxy" endpoints
- Server-side RLS for music data
- Rate limiting on API endpoints

### Audio Playback

Frontend uses HTML5 `<audio>` element:
```typescript
// ClassPlayback component
const audioPlayer = new Audio(track.audio_url);
audioPlayer.play();

// Sync with class timer
useEffect(() => {
  if (isPaused) audioPlayer.pause();
  else audioPlayer.play();
}, [isPaused]);
```

### Future Enhancement

- Add Jamendo API (commercial use requires paid license)
- Add Epidemic Sound Partner API (royalty-free catalog)
- Keep Musopen/FreePD as free base catalog
- Gradual migration path without breaking changes

---

## Excel Database Synchronization

### Migration from Excel

The comprehensive domain knowledge in `Pilates_Summary_Spreadsheet_teachingTracker_v10.xlsm` is migrated to PostgreSQL using:

```bash
cd backend
python scripts/migrate_excel.py --excel-path "/path/to/spreadsheet.xlsm" --validate
```

This script:
1. Parses all worksheets (Movements, Muscle Mappings, Sequencing Rules, etc.)
2. Validates data integrity
3. Transforms to normalized database schema
4. Imports with conflict resolution
5. Preserves Excel formulas as database functions

### Bi-directional Sync

For ongoing updates:

```python
from services.excel_sync import ExcelSyncService

sync = ExcelSyncService()

# Import changes from Excel
await sync.sync_from_excel("/path/to/updated_spreadsheet.xlsm")

# Export database to Excel
await sync.export_to_excel("/path/to/output_spreadsheet.xlsm")
```

Changes are detected intelligently with conflict resolution UI.

---

## Security and Compliance

### PII Tokenization

All personally identifiable information is tokenized using `utils/pii_tokenizer.py`:

```python
from utils.pii_tokenizer import tokenize_pii, detokenize_pii

# Store user data
tokenized_email = tokenize_pii(user_email)
await db.users.insert({"email_token": tokenized_email})

# Retrieve user data
email = detokenize_pii(db_record["email_token"])
```

Tokens are stored in `pii_tokens` table with AES-256 encryption.

### EU AI Act Compliance

All AI agent decisions are logged to `ai_decision_log` table with:
- Input parameters
- Model output
- Reasoning/explanation
- Confidence scores
- Timestamp and user context

Bias monitoring runs daily via cron job:

```bash
python scripts/check_model_drift.py --alert-threshold 0.15
```

### GDPR Compliance

User data export and deletion:

```python
# Export all user data
await export_user_data(user_id, format="json")

# Delete user (cascades to all related data)
await delete_user_account(user_id, reason="user_request")
```

---

## Testing Strategy

### Backend Tests

```bash
# Run all tests with coverage
pytest tests/ -v --cov=backend --cov-report=html

# Test sequencing rules
pytest tests/test_sequences.py -v

# Test AI agents
pytest tests/test_agents.py -v

# Test MCP integration
pytest tests/test_mcp.py -v

# Test compliance logging
pytest tests/test_compliance.py -v
```

### Frontend Tests

```bash
# Run all tests
npm test

# Watch mode for development
npm test -- --watch

# Component tests
npm test -- ClassBuilder.test.tsx

# Integration tests
npm test -- --testPathPattern=integration
```

### Database Tests

```bash
# Test database functions
supabase test db

# Test migrations
supabase db reset && supabase db push
```

---

## Important Implementation Notes

### When Working on Sequencing Logic

- **Always validate against safety rules** - Use `services/safety_validator.py`
- **Test with real data** - Import sample movements from Excel
- **Check muscle balance** - Use `calculate_muscle_balance()` function
- **Preserve spinal progression** - Flexion must precede extension
- **Document rule violations** - Log why a sequence was rejected

### When Working on AI Agents

- **Inherit from base_agent.py** - Ensures compliance logging
- **Use small models** - GPT-3.5-turbo or equivalent for cost efficiency
- **Implement graceful degradation** - Provide fallback when model fails
- **Log all decisions** - Required for EU AI Act transparency
- **Test bias monitoring** - Verify drift detection works

### When Working on Frontend

- **Match MVP exactly** - No design improvements or modernization
- **Copy existing styles** - Use same colors, fonts, layout
- **Preserve UX patterns** - Same drag-and-drop behavior
- **Test on same browsers** - Ensure compatibility matches MVP
- **Avoid adding features** - Only replicate existing functionality

### üö® CRITICAL: When Working on Class Builder Modal üö®

**ALWAYS reference `/docs/Visual_regression_baseline.md` when making ANY changes that impact the class builder modal.**

This document (commit `a53672e`) defines the approved visual appearance and behavior:

**Required Specifications:**
- Movement count: ~9 movements (AI-selected, NOT all 34 from database)
- Transition count: ~8 transitions (generated between movements)
- Transitions styled with:
  - Light background (`bg-burgundy/50`)
  - Italic text (`italic text-cream/70`)
  - Left accent border (`border-l-4 border-l-cream/40`)
  - Arrow icon (‚Üí)
- Muscle balance from database (NOT generic core/legs/arms)
- Balance Score calculated (NOT NaN)
- Primary Focus shows actual muscle group name from database

**Before Committing Changes:**
1. Read `/docs/Visual_regression_baseline.md`
2. Verify modal matches ALL specifications
3. Test that movement count is ~9 (not 34)
4. Verify transitions appear with correct styling
5. Check muscle balance shows database values
6. Confirm no visual regressions

**If Visual Regression Occurs:**
```bash
# Revert to baseline commit
git checkout a53672e -- frontend/src/components/class-builder/AIGenerationPanel.tsx
git checkout a53672e -- frontend/src/components/class-builder/ai-generation/SequenceResultsTab.tsx
git checkout a53672e -- frontend/src/components/class-builder/ai-generation/GeneratedResults.tsx
```

**Testing Checklist:**
- [ ] Movement count shows movements only (not total items)
- [ ] Transition count shows below movement count
- [ ] Transitions have lighter background than movements
- [ ] Transitions have left accent border (visual key)
- [ ] Transition text is italic
- [ ] Transition has arrow icon (‚Üí)
- [ ] Balance Score is not NaN
- [ ] Primary Focus shows actual muscle group name from database
- [ ] Muscle Balance chart shows database muscle groups

**This is a zero-tolerance policy. Always verify against Visual_regression_baseline.md before committing.**

### When Working with MCP

- **Cache aggressively** - 24-hour TTL for research results
- **Rate limit carefully** - Max 30 requests/minute
- **Attribute sources** - Always include source URLs
- **Validate quality** - Use quality scoring for MCP results
- **Handle failures gracefully** - Fallback to database knowledge

### When Working with Excel Data

- **Preserve business logic** - Excel formulas become database functions
- **Document macros** - VBA logic must be recreated in Python
- **Test sync carefully** - Bi-directional sync can cause conflicts
- **Validate integrity** - Check all required columns exist
- **Backup before migration** - Excel file is source of truth

---

## Common Development Workflows

### Adding a New Movement

1. Add to Excel spreadsheet (source of truth)
2. Run sync: `python scripts/sync_excel.py`
3. Verify in database: Check `movement_details` table
4. Update frontend cache: Refresh movement list in UI
5. Test sequencing: Ensure new movement respects safety rules

### Modifying Sequencing Rules

1. Update rule in `database/functions/validate_sequence.sql`
2. Write test case in `tests/test_sequences.py`
3. Apply migration: `alembic upgrade head`
4. Update documentation: Add rule to this CLAUDE.md file
5. Test with agent: Verify sequence agent respects new rule

### Adding MCP Research Capability

1. Identify research need (e.g., finding warm-up exercises)
2. Add method to `services/mcp_client.py`
3. Implement caching in Redis
4. Add quality scoring
5. Test with real queries
6. Integrate into research agent

### Deploying Changes

1. Run full test suite: `pytest && npm test`
2. Check compliance: `python scripts/check_compliance.py`
3. Build frontend: `npm run build`
4. Apply migrations: `alembic upgrade head`
5. Deploy backend: Update Docker container
6. Deploy frontend: Upload to hosting
7. Monitor logs: Check for errors in first hour

---

## External Resources

### Documentation
- **FastAPI**: https://fastapi.tiangolo.com/
- **React**: https://react.dev/
- **Supabase**: https://supabase.com/docs
- **MCP Protocol**: https://modelcontextprotocol.io/
- **EU AI Act**: https://artificialintelligenceact.eu/

### Domain Knowledge
- **Pilates Method Alliance**: https://www.pilatesmethod.com/
- **Balanced Body University**: https://www.pilates.com/
- **Classical Pilates**: Reference the 34 movements in Excel database

### Project Files
- **Excel Database**: `/Users/lauraredmond/Documents/Bassline/Admin/7. Product/Design Documentation/Pilates_Summary_Spreadsheet_teachingTracker_v10.xlsm`
- **MCP Integration Plan**: `/Users/lauraredmond/Documents/Bassline/Admin/7. Product/Design Documentation/MCP_Excel_Integration_Plan.md`

---

## Troubleshooting

### Sequence Validation Failing

**Problem:** Valid sequence rejected by safety validator
**Solution:** Check `ai_decision_log` table for rejection reason. Most common: spinal progression rule (flexion must precede extension).

### MCP Playwright Not Responding

**Problem:** Research agent timeouts
**Solution:**
1. Check MCP server is running: `ps aux | grep playwright`
2. Restart server: `npx @modelcontextprotocol/server-playwright`
3. Check rate limits in `config/mcp_config.yaml`
4. Clear Redis cache: `redis-cli FLUSHDB`

### Excel Sync Conflicts

**Problem:** Bi-directional sync shows conflicts
**Solution:** Excel is source of truth. Use `sync_from_excel()` to override database with Excel data. Review conflicts in sync UI before applying.

### Frontend Not Matching MVP

**Problem:** UI looks different from original MVP
**Solution:**
1. Compare screenshots side-by-side
2. Check CSS matches exactly (colors, fonts, spacing)
3. Test drag-and-drop behavior matches
4. Verify same browser/device as MVP testing

### AI Agent Bias Detected

**Problem:** Model drift monitoring alerts
**Solution:**
1. Review `bias_monitoring` table for specific metrics
2. Check if training data has changed
3. Consider retraining or model version update
4. Document in compliance logs

---

## Performance Considerations

### Database Queries
- Use indexes on `movement_details.difficulty` and `movement_details.primary_muscles`
- Cache frequently accessed movements in Redis (TTL: 1 hour)
- Use database functions for complex sequencing logic (faster than Python)

### Frontend Rendering
- Virtualize long movement lists (react-window)
- Debounce drag-and-drop events
- Lazy load movement details
- Cache API responses in React Query

### MCP Research
- Cache all research results (TTL: 24 hours)
- Batch requests when possible
- Use quality scoring to filter results early
- Implement request pooling (max 3 concurrent)

---

## Session Progress & Next Steps

### Session 7: User Authentication & Profile ‚úÖ COMPLETED

**Date:** November 22-24, 2025
**Status:** ‚úÖ Complete

**Completed:**
- ‚úÖ Created authentication system (JWT tokens, password hashing)
- ‚úÖ Built backend auth endpoints (`/api/auth/register`, `/api/auth/login`, etc.)
- ‚úÖ Created frontend auth pages (Login, Register, ResetPassword)
- ‚úÖ Implemented AuthContext for global auth state
- ‚úÖ Added ProtectedRoute wrapper for authenticated routes
- ‚úÖ Created Supabase database tables (`user_profiles`, `user_preferences`)
- ‚úÖ Fixed Render deployment (added missing dependencies to `requirements-production.txt`)
- ‚úÖ Fixed Netlify deployment (removed unused TypeScript parameters)
- ‚úÖ **CONFIRMED: Successfully writing user data to Supabase** (commit 9a1f8b5)
- ‚úÖ Email confirmation page and production redirect URL fixed
- ‚úÖ Enhanced user profile fields added to registration
- ‚úÖ Content Security Policy implemented
- ‚úÖ Password reset flow completed with confirmation page
- ‚úÖ Console security warnings resolved
- ‚úÖ Account deletion feature added (GDPR right to be forgotten)

### Session 8: Settings & Preferences ‚úÖ COMPLETED

**Date:** November 24-25, 2025
**Status:** ‚úÖ Complete (with known issues)

**Completed:**
- ‚úÖ Profile editing functionality (commit 54d36cb)
- ‚úÖ Password change functionality (commit 54d36cb)
- ‚úÖ Account deletion with GDPR compliance (commit 93ed31c)
- ‚úÖ Notification preferences UI and API
- ‚úÖ Privacy settings (analytics, data sharing toggles)
- ‚úÖ AI strictness level preferences
- ‚úÖ Default class duration settings
- ‚úÖ Music preference placeholders (for Session 10)
- ‚úÖ GDPR & EU AI Act compliance system:
  - ‚úÖ Created 4 compliance database tables (ropa_audit_log, ai_decision_log, bias_monitoring, model_drift_log)
  - ‚úÖ Built PII logging middleware (tracks all PII transactions)
  - ‚úÖ Built AI decision logger (tracks AI decisions with reasoning)
  - ‚úÖ Created 5 compliance API endpoints (/api/compliance/*)
  - ‚úÖ Updated auth endpoints to log PII transactions
  - ‚úÖ Added compliance dashboard UI to Settings page (commits cc1bd99, 7104fbf, 60f7654)

**Production URLs:**
- Frontend: https://basslinemvp.netlify.app
- Backend API: https://pilates-class-generator-api3.onrender.com
- Settings page: https://basslinemvp.netlify.app/settings

**Known Issues:**
- ‚ö†Ô∏è **GDPR Article 15 Data Download - HTTP 500 Error**
  - **Issue**: `/api/compliance/my-data` endpoint fails when user clicks "Download My Data" button
  - **Symptoms**: Returns HTTP 500 error in production
  - **Attempted Fixes**:
    - ‚úó JWT token refresh (logout/login) - did not resolve
    - ‚úó localStorage.clear() - did not resolve
  - **Database Status**: All 4 compliance tables exist and are accessible ‚úì
  - **Backend Status**: API is healthy and deployed ‚úì
  - **Next Steps**:
    - Check Render backend logs for actual 500 error details
    - Verify Row-Level Security (RLS) policies on compliance tables
    - Test endpoint with valid JWT token directly
    - Verify PIILogger.log_data_export() middleware call

**Resolved Issues:**
- ‚úÖ **Supabase Registration Rate Limit** - RESOLVED (2025-11-28)
  - User upgraded to paid Supabase plan ($25)
  - Rate limits removed after plan upgrade propagated
  - **‚ö†Ô∏è DO NOT BRING UP THIS ISSUE AGAIN - IT IS FULLY RESOLVED**

**Deferred Testing:**
- ‚è∏Ô∏è **AI Compliance System Testing** - Deferred to future session
  - **Reason**: AI behavior not yet incorporated into application
  - **What to Test**: AI decision logging, bias monitoring, model drift detection with real AI operations
  - **When to Test**: After Session 11 (OpenAI GPT Integration) when AI agents are actively making decisions
  - **Action Item**: Add to appropriate future session in "Pilates App Daily Sessions Final" document

### Session 9: Music Integration ‚úÖ COMPLETED

**Date:** November 26, 2025
**Status:** ‚úÖ Complete

**Completed:**
- ‚úÖ Database schema for music tracks and playlists (migration 003_music_integration.sql)
- ‚úÖ Internet Archive as music source (14 verified public domain classical tracks)
- ‚úÖ 8 curated playlists covering all stylistic periods
- ‚úÖ Backend music API endpoints (`/api/music/playlists`, `/api/music/tracks`, `/api/music/health`)
- ‚úÖ Frontend music playback integration (HTML5 audio in ClassPlayback component)
- ‚úÖ Fixed CORS issues and streaming URL whitelist
- ‚úÖ Fixed browser autoplay blocking with manual enable button
- ‚úÖ Fixed audio element lifecycle (src being lost on re-render)
- ‚úÖ Replaced temporary user ID system with authenticated user ID

**Tracks Added (14 total):**
- **Impressionist:** Clair de Lune, Arabesque No. 1 (Debussy)
- **Romantic:** Minute Waltz, Nocturne Op. 9 No. 2 (Chopin)
- **Classical:** Eine Kleine Nachtmusik, Symphony No. 40 (Mozart)
- **Baroque:** Brandenburg Concerto No. 3, Air on G String, Minuet in G (Bach)
- **Modern:** Gymnop√©die No. 1 (Satie), Appalachian Spring (Copland)
- **Contemporary:** Ambient meditation track
- **Celtic Traditional:** Anderson's Reel, Humours of Lissadell

**Production URLs:**
- Frontend: https://basslinemvp.netlify.app
- Backend API: https://pilates-class-generator-api3.onrender.com
- Music health check: https://pilates-class-generator-api3.onrender.com/api/music/health

**Key Technical Fixes:**
1. Added `archive.org` to ALLOWED_STREAMING_DOMAINS whitelist
2. Fixed audio element being recreated and losing src URL (changed useEffect deps)
3. Used 'playing' event instead of 'play' event for accurate playback detection
4. Added manual "Click to Enable Music" button for browser autoplay blocking
5. Replaced getTempUserId() with real authenticated user from AuthContext

**Next Steps (Future Sessions):**
- Add more tracks from Internet Archive collections (URLs documented in CLAUDE.md)
- Implement playlist editing/customization for users
- Add music volume controls in playback UI
- Consider adding music fade in/out between movements

### Session 10: Jentic Integration - Phase 1 (Core Architecture) ‚úÖ COMPLETED

**Date:** November 27-28, 2025
**Status:** ‚úÖ Complete (Real Jentic Code Integrated)

**Goal:** Integrate Jentic's Standard Agent + Arazzo Engine with educational documentation for client relationship and future project patterns.

**Strategic Context:**
- Jentic is a client of Bassline
- Deep understanding of their codebase needed for business relationship
- Learning industry-standard agentic patterns for future projects
- Educational focus: annotate all Jentic code vs Bassline customizations
- **CRITICAL**: Use REAL Jentic code from GitHub (not stubs, not placeholders)

**Completed:**
- ‚úÖ Deep study of standard-agent repository (github.com/jentic/standard-agent)
- ‚úÖ Deep study of arazzo-engine repository (github.com/jentic/arazzo-engine)
- ‚úÖ Created comprehensive Jentic Architecture Guide (`docs/JENTIC_ARCHITECTURE.md`)
  - StandardAgent's Plan‚ÜíExecute‚ÜíReflect reasoning loop explained
  - Arazzo workflow DSL and execution model documented
  - Integration patterns with code examples
  - Business model analysis (platform gravity, vendor dependencies)
  - Reusable patterns library
- ‚úÖ **REAL JENTIC CODE INTEGRATION** (Commit 706fea9)
  - Updated `orchestrator/requirements.txt` to install from GitHub repos
  - Rewrote `orchestrator/agent/bassline_agent.py` with real StandardAgent inheritance
  - Updated `orchestrator/agent/tools.py` with real ArazzoRunner integration
  - Heavy educational annotations throughout code ("JENTIC PATTERN" vs "BASSLINE CUSTOM")
  - 5 new educational docs created (JENTIC_REAL_CODE_ANALYSIS.md, etc.)
- ‚úÖ Removed ALL placeholder/stub code
- ‚úÖ Production-ready integration using real Jentic libraries
- ‚úÖ Committed to GitHub with detailed documentation

**Key Technical Achievements:**

1. **Real Jentic Installation** (`orchestrator/requirements.txt`)
   ```python
   # BEFORE: Placeholders and comments
   # AFTER: Real GitHub installation
   git+https://github.com/jentic/standard-agent.git@main
   git+https://github.com/jentic/arazzo-engine.git@main#subdirectory=runner
   ```

2. **BasslinePilatesCoachAgent** (`orchestrator/agent/bassline_agent.py`)
   - Extends real StandardAgent class from Jentic
   - Uses real LiteLLM, ReWOOReasoner, JustInTimeToolingBase
   - Composition pattern: LLM + Tools + Reasoner + Memory
   - Inherits solve() method, state management, memory handling
   - Heavily annotated with educational comparisons

3. **Real Arazzo Workflow Execution** (`orchestrator/agent/tools.py`)
   - Real ArazzoRunner.from_arazzo_path() initialization
   - Real arazzo_runner.execute_workflow() calls
   - Graceful fallback when workflow files missing
   - Annotated with Jentic pattern documentation

4. **Educational Documentation** (`docs/JENTIC_*.md`)
   - 5 comprehensive guides explaining Jentic architecture
   - Side-by-side comparison of Jentic code vs our customization
   - Reusable patterns for future projects
   - Deep understanding of StandardAgent internals

**Phase 1 Deliverables (ALL COMPLETE):**
- ‚úÖ Python orchestration service scaffold with real Jentic integration
- ‚úÖ Heavily commented code showing Jentic patterns vs Bassline customizations
- ‚úÖ Real StandardAgent + ArazzoRunner code (not stubs)
- ‚úÖ Educational documentation for client relationship
- ‚úÖ Apache 2.0 license compliance (both Jentic repos)
- ‚úÖ Production-ready foundation for future sessions

**Next Steps (Future Sessions):**
- Document existing Bassline APIs in OpenAPI 3.0 spec
- Create Arazzo workflow V1 (4-step class generation YAML file)
- Test real workflow execution with backend APIs
- Deploy orchestrator service to Render
- Wire frontend to new orchestration service
- Full end-to-end testing with real agent reasoning

**Technical Stack:**
```
Frontend (React) ‚Üí Python Orchestration Service (Render) ‚Üí Existing Backend (Render)
                     ‚Üì
              ‚úÖ REAL StandardAgent + Arazzo (from GitHub)
                     ‚Üì
              Supabase + APIs
```

**Architecture Documentation:**
- See `/docs/JENTIC_MASTER.md` for comprehensive Jentic integration guide (single source of truth)
  - Section 2: Architecture (StandardAgent, Arazzo Engine, component diagrams)
  - Section 3: Core Concepts (ReWOO, LiteLLM, JustInTimeToolingBase)
  - Section 4: Integration with Bassline (real implementation examples)
  - Section 5: Arazzo Workflows (complete workflow guide)
  - Sections 6-10: Practical examples, best practices, troubleshooting, reference
  - Old documentation archived in `/docs/archive/jentic/` for historical reference only

**Key Learning (Dual Goals Achieved):**
1. ‚úÖ **Production-Ready**: Real Jentic code integrated, not placeholders
2. ‚úÖ **Educational**: Deep understanding of Jentic's architecture through real implementation
3. ‚úÖ **Client Relationship**: Intimate knowledge of Jentic codebase for business partnership
4. ‚úÖ **Future Projects**: Reusable agentic patterns library created

---

### Session 11: Data Model Expansion (6-Section Class Structure) ‚úÖ COMPLETED

**Date:** November 29, 2025
**Status:** ‚úÖ Complete

**Goal:** Add all 6 Pilates class sections for complete class flow

**Completed:**
- ‚úÖ Created 5 new database tables (preparation_scripts, warmup_routines, cooldown_sequences, closing_meditation_scripts, closing_homecare_advice)
- ‚úÖ Created database migration with comprehensive seed data
- ‚úÖ Built 10 new backend API endpoints for class sections
- ‚úÖ Extended frontend ClassPlayback component for all 6 section types
- ‚úÖ Updated MovementDisplay with teleprompter-style rendering
- ‚úÖ Created classAssembly.ts service with SECTION_DURATIONS constants
- ‚úÖ Fixed AI sequence generation regression (9 movements + 8 transitions)
- ‚úÖ Combined AI-generated movements with 6-section structure
- ‚úÖ Documented Visual_regression_baseline.md policy in CLAUDE.md
- ‚úÖ Deployed to production (Netlify + Render)

**Context:**
Pilates classes have 6 distinct sections:
  1. Preparation (Pilates principles, breathing) - 4 minutes
  2. Warm-up (safety-focused routines) - 3 minutes
  3. Main movements (AI-selected) - variable (total - 15 min overhead)
  4. Transitions (AI-generated between movements) - 1 min each
  5. Cool-down (stretches, recovery) - 3 minutes
  6a. Closing Meditation - 4 minutes
  6b. Closing HomeCare Advice - 1 minute

**Database Tables Created:**

#### 1. Movement Levels Table (Normalized)
```sql
CREATE TABLE movement_levels (
    id UUID PRIMARY KEY,
    movement_id UUID REFERENCES movements(id),
    level_number INTEGER,  -- 1, 2, 3, 4 (full)
    level_name VARCHAR(50),  -- "Level 1", "Level 2", etc.

    -- Level-specific content
    narrative TEXT,
    setup_position VARCHAR(255),
    watch_out_points TEXT[],
    teaching_cues JSONB,
    visual_cues TEXT[],
    muscle_groups JSONB,
    duration_seconds INTEGER,

    UNIQUE(movement_id, level_number)
);
```

**Note:** Not all movements have all 4 levels - store only what exists per movement.

#### 2. Class Section Tables (6 new tables)

**Priority 1: Preparation Scripts**
```sql
CREATE TABLE preparation_scripts (
    script_name VARCHAR(255),
    script_type VARCHAR(50),  -- 'centering', 'breathing', 'principles'
    narrative TEXT,
    key_principles TEXT[],  -- Pilates principles covered
    duration_seconds INTEGER,
    breathing_pattern VARCHAR(100),
    breathing_focus VARCHAR(255),
    difficulty_level VARCHAR(50)
);
```

**Priority 2: Warm-up Routines**
```sql
CREATE TABLE warmup_routines (
    routine_name VARCHAR(255),
    focus_area VARCHAR(100),  -- 'spine', 'hips', 'shoulders', 'full_body'
    narrative TEXT,
    movements JSONB,  -- Simple movements: neck rolls, shoulder circles
    duration_seconds INTEGER,
    contraindications TEXT[],
    modifications JSONB,
    difficulty_level VARCHAR(50)
);
```

**Priority 3:** Movements + Transitions (already exist)

**Priority 4: Cool-down Sequences**
```sql
CREATE TABLE cooldown_sequences (
    sequence_name VARCHAR(255),
    intensity_level VARCHAR(50),  -- 'gentle', 'moderate', 'deep'
    narrative TEXT,
    stretches JSONB,
    duration_seconds INTEGER,
    target_muscles TEXT[],
    recovery_focus VARCHAR(255)
);
```

**Priority 5: Closing-Meditation Scripts**
```sql
CREATE TABLE closing_meditation_scripts (
    script_name VARCHAR(255),
    meditation_theme VARCHAR(100),  -- 'body_scan', 'gratitude', 'breath'
    script_text TEXT,
    breathing_guidance TEXT,
    duration_seconds INTEGER,
    post_intensity VARCHAR(50)  -- What came before: 'high', 'moderate', 'low'
);
```

**Priority 6: Closing-Home Care Advice** (NEW)
```sql
CREATE TABLE closing_homecare_advice (
    advice_name VARCHAR(255),
    focus_area VARCHAR(100),  -- 'spine_care', 'injury_prevention', 'recovery'
    advice_text TEXT,
    actionable_tips TEXT[],
    duration_seconds INTEGER DEFAULT 60,
    related_to_class_focus BOOLEAN DEFAULT false
);
```

#### 3. New API Endpoints (Phase 2)

**Movement Levels:**
```
GET  /api/movements/{id}/levels              # Get all levels
GET  /api/movements/{id}/levels/{level_num}  # Get specific level
POST /api/movements/{id}/levels              # Admin: Add level
```

**Class Sections:**
```
GET  /api/class-sections/preparation
GET  /api/class-sections/warmup
GET  /api/class-sections/cooldown
GET  /api/class-sections/closing-meditation
GET  /api/class-sections/closing-homecare
```

**User Preferences (extend):**
```
PUT  /api/users/{id}/preferences
# Add fields:
# - delivery_format: "text" | "audio" | "visual" (Phase 3)
# - preferred_movement_level: "beginner" | "intermediate" | "advanced"
# - show_full_progression: boolean (show L1‚ÜíL2‚ÜíL3‚ÜíFull in class)
```

#### 4. Updated Arazzo Workflow (Phase 2)

Expands from 4 steps to 10 steps:

```yaml
workflowId: assemble_complete_pilates_class_v2

steps:
  1. get_user_profile
  2. select_preparation_script     # NEW
  3. select_warmup_routine         # NEW
  4. select_movements_with_levels  # ENHANCED
  5. generate_transitions          # Existing
  6. select_cooldown_sequence      # NEW
  7. select_closing_meditation     # NEW
  8. select_homecare_advice        # NEW
  9. select_music_for_all_sections # ENHANCED
  10. assemble_and_save_class      # ENHANCED
```

**Data Flow Example:**
```yaml
# Step 4: Select movements with user's level preferences
- stepId: select_movements_with_levels
  parameters:
    - name: difficulty
      value: $inputs.difficulty
    - name: show_full_progression
      value: $steps.get_user_profile.outputs.body.show_full_progression
    # If true: returns L1‚ÜíL2‚ÜíL3‚ÜíFull progression in narrative
    # If false: returns only appropriate single level
```

---

### Session 11.5: Jentic Formalization & Standardization ‚úÖ COMPLETE

**Date:** December 1, 2025
**Status:** ‚úÖ Complete - Full Jentic Integration

**Goal:** Fully leverage Jentic's StandardAgent and Arazzo Engine patterns to ensure maximum scalability through code standardization.

**Strategic Rationale:**
> "Standardizing code is the best way to ensure it is easily scalable. We need to leverage Jentic's inserted code to achieve that goal to the best of our ability." - Project Owner

**Summary:** Successfully completed full Jentic integration with production-ready OpenAPI specs, Arazzo workflows, and comprehensive educational documentation. Frontend wired to orchestrator with hybrid fallback approach.

**Why This Session Matters:**
1. **Scalability First**: Standardized code using industry patterns = easily scalable across projects
2. **Client Relationship**: Deepens understanding of Jentic's architecture (Jentic is our client)
3. **Educational Goal**: Clear, simple explanations of HOW Jentic integrates and WHY it brings advantages
4. **Production Quality**: Replace any remaining custom implementations with proven Jentic patterns

**Current State Analysis:**

**‚úÖ What We've Done (Session 10):**
- Real StandardAgent + Arazzo libraries installed from GitHub
- BasslinePilatesCoachAgent extends StandardAgent correctly
- ArazzoRunner integrated with real workflow execution
- Heavy educational annotations ("JENTIC PATTERN" vs "BASSLINE CUSTOM")
- 5 comprehensive documentation guides created

**üéØ What Needs Formalization:**
1. **Arazzo Workflows**: We have stubs, need complete YAML workflows
2. **OpenAPI Specs**: Backend APIs not yet documented in OpenAPI 3.0 format
3. **Workflow-First Architecture**: Need to move more logic from code into declarative Arazzo workflows
4. **StandardAgent Usage**: Maximize use of inherited StandardAgent patterns vs custom code
5. **Educational Documentation**: Add clear, simple explanations for all integrations

**Implementation Plan:**

**Step 1: Audit Current Code Against Jentic Patterns** (2 hours)
- Review all custom agent code in `backend/agents/` and `orchestrator/agent/`
- Identify logic that can be moved to Arazzo workflows (declarative > imperative)
- Document deviations from StandardAgent patterns with justifications
- Create checklist of standardization opportunities

**Educational Focus:**
- **WHY**: Jentic's StandardAgent provides battle-tested reasoning loops, memory management, and tool orchestration that we don't need to reinvent
- **HOW**: By inheriting from StandardAgent, we get Plan‚ÜíExecute‚ÜíReflect for free, reducing custom code
- **ADVANTAGE**: Less code to maintain, proven patterns, easier onboarding for new developers

**Step 2: Complete OpenAPI 3.0 Specifications** (3 hours)
- Document all `/api/agents/*` endpoints in OpenAPI format
- Document all `/api/class-sections/*` endpoints
- Document all `/api/movements/*` endpoints
- Add request/response schemas
- Include authentication requirements
- Save as `backend/openapi/bassline-api-v1.yaml`

**Educational Focus:**
- **WHY**: Arazzo workflows need OpenAPI specs to call our APIs programmatically
- **HOW**: OpenAPI provides machine-readable API contracts that Arazzo can execute
- **ADVANTAGE**: Arazzo can orchestrate complex workflows across multiple API calls without custom code

**Step 3: Create Complete Arazzo Workflows** (4 hours)

**Current State**: Stub workflow files exist but not functional
**Target State**: Production-ready declarative workflows

Create `orchestrator/workflows/pilates_class_generation_v1.arazzo.yaml`:

```yaml
arazzo: 1.0.0
info:
  title: Pilates Class Generation Workflow
  version: 1.0.0
  description: Complete 6-section Pilates class generation using AI agents

sourceDescriptions:
  - name: bassline-api
    url: /backend/openapi/bassline-api-v1.yaml
    type: openapi

workflows:
  - workflowId: generate_complete_class
    description: Generate a complete Pilates class with all 6 sections

    inputs:
      type: object
      properties:
        user_id:
          type: string
        difficulty:
          type: string
          enum: [Beginner, Intermediate, Advanced]
        duration_minutes:
          type: integer
        focus_areas:
          type: array
          items:
            type: string

    steps:
      # Step 1: Fetch user preferences
      - stepId: get_user_profile
        operationId: getUserProfile
        parameters:
          - name: user_id
            in: path
            value: $inputs.user_id
        outputs:
          preferred_music_style: $response.body.preferred_music_style
          ai_strictness: $response.body.ai_strictness

      # Step 2: Select preparation script (Section 1)
      - stepId: select_preparation
        operationId: getPreparationScripts
        parameters:
          - name: difficulty
            in: query
            value: $inputs.difficulty
          - name: script_type
            in: query
            value: centering
        outputs:
          preparation_script: $response.body[0]

      # Step 3: Select warmup routine (Section 2)
      - stepId: select_warmup
        operationId: getWarmupRoutines
        parameters:
          - name: focus_area
            in: query
            value: full_body
          - name: difficulty
            in: query
            value: $inputs.difficulty
        outputs:
          warmup_routine: $response.body[0]

      # Step 4: Generate AI sequence (Section 3: Movements + Transitions)
      - stepId: generate_sequence
        operationId: generateSequence
        parameters:
          - name: target_duration_minutes
            in: body
            value: $inputs.duration_minutes
          - name: difficulty_level
            in: body
            value: $inputs.difficulty
          - name: focus_areas
            in: body
            value: $inputs.focus_areas
          - name: strictness_level
            in: body
            value: $steps.get_user_profile.outputs.ai_strictness
        outputs:
          movements: $response.body.data.sequence
          muscle_balance: $response.body.data.muscle_balance

      # Step 5: Select music playlist
      - stepId: select_music
        operationId: selectMusic
        parameters:
          - name: class_duration_minutes
            in: body
            value: $inputs.duration_minutes
          - name: energy_level
            in: body
            value: 0.6
          - name: stylistic_period
            in: body
            value: $steps.get_user_profile.outputs.preferred_music_style
        outputs:
          music_playlist: $response.body.data.playlist

      # Step 6: Select cooldown sequence (Section 4)
      - stepId: select_cooldown
        operationId: getCooldownSequences
        parameters:
          - name: intensity
            in: query
            value: moderate
        outputs:
          cooldown_sequence: $response.body[0]

      # Step 7: Select closing meditation (Section 5)
      - stepId: select_meditation
        operationId: getClosingMeditations
        parameters:
          - name: theme
            in: query
            value: body_scan
          - name: post_intensity
            in: query
            value: moderate
        outputs:
          meditation_script: $response.body[0]

      # Step 8: Select homecare advice (Section 6)
      - stepId: select_homecare
        operationId: getHomecareAdvice
        parameters:
          - name: focus_area
            in: query
            value: spine_care
        outputs:
          homecare_advice: $response.body[0]

      # Step 9: Assemble complete class
      - stepId: assemble_class
        operationId: saveGeneratedClass
        parameters:
          - name: user_id
            in: body
            value: $inputs.user_id
          - name: preparation
            in: body
            value: $steps.select_preparation.outputs.preparation_script
          - name: warmup
            in: body
            value: $steps.select_warmup.outputs.warmup_routine
          - name: movements
            in: body
            value: $steps.generate_sequence.outputs.movements
          - name: cooldown
            in: body
            value: $steps.select_cooldown.outputs.cooldown_sequence
          - name: meditation
            in: body
            value: $steps.select_meditation.outputs.meditation_script
          - name: homecare
            in: body
            value: $steps.select_homecare.outputs.homecare_advice
          - name: music_playlist
            in: body
            value: $steps.select_music.outputs.music_playlist
          - name: muscle_balance
            in: body
            value: $steps.generate_sequence.outputs.muscle_balance

    outputs:
      complete_class_id: $steps.assemble_class.outputs.class_id
      total_duration: $steps.assemble_class.outputs.total_duration
      sections_count: 6
```

**Educational Focus:**
- **WHY**: Declarative workflows are easier to test, debug, and modify than imperative code
- **HOW**: Arazzo workflows describe WHAT to do (call these APIs in this order), not HOW to do it (connection pooling, retry logic, etc.)
- **ADVANTAGE**: Non-developers (domain experts) can understand and even modify workflows; no Python knowledge required

**Step 4: Refactor Backend Agents to Use StandardAgent Patterns** (3 hours)

**Current Custom Code** (`backend/agents/sequence_agent.py`):
```python
class SequenceAgent:
    def __init__(self):
        self.model = get_openai_client()

    async def generate_sequence(self, params):
        # Custom reasoning loop
        prompt = self._build_prompt(params)
        response = await self.model.complete(prompt)
        return self._parse_response(response)
```

**Standardized with Jentic** (new):
```python
from jentic.standard_agent import StandardAgent
from jentic.reasoners import ReWOOReasoner

# JENTIC PATTERN: Inherit from StandardAgent for free Plan‚ÜíExecute‚ÜíReflect
class SequenceAgent(StandardAgent):
    """
    EDUCATIONAL NOTE: By extending StandardAgent, we inherit:
    - Plan‚ÜíExecute‚ÜíReflect reasoning loop (proven pattern)
    - State management and memory handling
    - Tool orchestration infrastructure
    - Logging and observability hooks

    BASSLINE CUSTOM: We only add domain-specific logic:
    - Pilates sequencing rules
    - Muscle balance calculations
    - Safety validation
    """

    def __init__(self):
        super().__init__(
            reasoner=ReWOOReasoner(),  # JENTIC: ReWOO = Reasoning WithOut Observation
            tools=self._get_pilates_tools()
        )

    def _get_pilates_tools(self):
        """BASSLINE CUSTOM: Pilates-specific tools"""
        return [
            self._validate_safety_rules,
            self._calculate_muscle_balance,
            self._check_prerequisites
        ]

    async def solve(self, task: str) -> dict:
        """
        JENTIC PATTERN: Inherited solve() method handles:
        1. Planning: Break task into steps
        2. Execution: Call tools as needed
        3. Reflection: Verify result quality

        We don't reimplement reasoning - we inherit it!
        """
        return await super().solve(task)
```

**Educational Focus:**
- **WHY**: StandardAgent encapsulates years of research on effective agent reasoning patterns
- **HOW**: We compose our agent with a Reasoner (brain) + Tools (hands) instead of custom loops
- **ADVANTAGE**: Proven reasoning patterns, automatic observability, easier debugging, less code

**Step 5: Wire Frontend to Orchestrator Service** (2 hours)

Update `frontend/src/services/api.ts`:

```typescript
// BEFORE (Session 10): Direct calls to backend
export const agentsApi = {
  generateSequence: (params) =>
    axios.post(`${BACKEND_URL}/api/agents/generate-sequence`, params)
}

// AFTER (Session 11.5): Route through Jentic orchestrator
export const agentsApi = {
  generateSequence: (params) =>
    // JENTIC PATTERN: Orchestrator handles Arazzo workflow execution
    // ADVANTAGE: Workflow changes don't require frontend redeployment
    axios.post(`${ORCHESTRATOR_URL}/api/workflows/generate_complete_class`, {
      inputs: params
    })
}
```

**Educational Focus:**
- **WHY**: Orchestrator provides a stable API even as underlying workflows evolve
- **HOW**: Frontend calls one endpoint; orchestrator manages complex multi-step workflows
- **ADVANTAGE**: Decoupling allows backend/workflow changes without frontend updates

**Expected Deliverables:**

1. ‚úÖ **Audit Report**: `docs/JENTIC_STANDARDIZATION_AUDIT.md`
   - Lists all custom code vs Jentic patterns
   - Justifications for any necessary deviations
   - Standardization opportunities identified

2. ‚úÖ **OpenAPI Specifications**: `backend/openapi/bassline-api-v1.yaml`
   - Complete API documentation
   - All endpoints machine-readable
   - Ready for Arazzo consumption

3. ‚úÖ **Production Arazzo Workflows**: `orchestrator/workflows/*.arazzo.yaml`
   - Complete class generation workflow
   - All 6 sections orchestrated
   - Tested and validated

4. ‚úÖ **Refactored Agents**: Updated `backend/agents/*` files
   - All agents extend StandardAgent
   - Custom logic moved to tools
   - Educational annotations throughout

5. ‚úÖ **Updated Frontend**: Modified `frontend/src/services/api.ts`
   - Routes through orchestrator
   - Simplified API calls
   - Error handling standardized

6. ‚úÖ **Educational Documentation**: Updated `docs/JENTIC_*.md`
   - Clear explanations of WHY Jentic brings advantages
   - Simple HOW guides for each integration point
   - Comparison of before/after code

**Success Criteria:**

- [ ] **100% Jentic Compliance**: All agents extend StandardAgent (no custom reasoning loops)
- [ ] **Declarative Workflows**: Class generation fully defined in Arazzo YAML (testable, modifiable)
- [ ] **OpenAPI Complete**: All backend APIs documented and machine-readable
- [ ] **Frontend Decoupled**: Routes through orchestrator, not directly to backend
- [ ] **Educational Goal Met**: User can explain to others HOW and WHY Jentic integrates
- [ ] **Scalability Achieved**: Code follows industry standards, easily portable to future projects

**Testing Plan:**

1. **Workflow Validation**: Use Arazzo validator to check YAML syntax
2. **Integration Testing**: Execute workflow end-to-end with real APIs
3. **Performance Testing**: Compare workflow execution time vs custom code
4. **Documentation Review**: User reviews educational annotations for clarity
5. **Portability Test**: Create new agent for different domain using same patterns

**Impact on Project Goals:**

**Goal 1 (Production-Ready Platform):**
- ‚úÖ Improves: Standardized patterns = fewer bugs, easier maintenance
- ‚úÖ Improves: Declarative workflows = faster feature development

**Goal 2 (Learn Jentic Architecture):**
- ‚úÖ Maximizes: Deep hands-on experience with StandardAgent composition
- ‚úÖ Maximizes: Real-world Arazzo workflow creation and debugging
- ‚úÖ Maximizes: Clear understanding of advantages for future client work

**Why This Session is High Priority:**
> "Standardizing code is the best way to ensure it is easily scalable."

Without this formalization:
- ‚ùå We have Jentic code but don't leverage it fully
- ‚ùå Custom implementations mask Jentic's proven patterns
- ‚ùå Future projects won't benefit from standardization investment
- ‚ùå Educational goal incomplete (know WHAT Jentic does, not WHY/HOW)

With this formalization:
- ‚úÖ Jentic patterns become our default development style
- ‚úÖ Every new feature starts with "Can Arazzo handle this declaratively?"
- ‚úÖ Future projects copy standardized patterns, not custom code
- ‚úÖ Educational goal complete (can teach others Jentic advantages)

---

### Session 11.75: Movement Data Population (Watch Points, Visual Cues, Level Flags) ‚úÖ COMPLETED

**Date:** December 2, 2025
**Status:** ‚úÖ Complete - **SQL Migrations Executed by User on December 1, 2025**

**Goal:** Populate movement table with safety warnings, visual cues, and level existence flags from Excel source data

**Completed:**
- ‚úÖ Created SQL scripts to populate watch_out_points and visual_cues for all 34 movements
- ‚úÖ Created database migration to convert level fields from TEXT to VARCHAR(1) Y/N flags
- ‚úÖ Added missing level_3_description column
- ‚úÖ Populated level flags (L1, L2, L3, FV) for all movements based on Excel data
- ‚úÖ Updated backend Movement Pydantic model with new fields
- ‚úÖ Updated frontend TypeScript interfaces (Movement, PlaybackMovement)
- ‚úÖ Created comprehensive documentation (README_LEVEL_FLAGS_UPDATE.md)
- ‚úÖ Committed all changes to GitHub (commits 04d8653, 9d41cee)
- ‚úÖ **User executed all 3 SQL migrations in Supabase on December 1, 2025**

**Database Changes:**

**Migration 011:** Convert Level Fields to Flags
- Added `level_3_description` column (was missing from original schema)
- Converted level description fields from TEXT to VARCHAR(1):
  - `level_1_description`: TEXT ‚Üí VARCHAR(1) with CHECK constraint (Y/N only)
  - `level_2_description`: TEXT ‚Üí VARCHAR(1) with CHECK constraint
  - `level_3_description`: VARCHAR(1) with CHECK constraint (new)
  - `full_version_description`: TEXT ‚Üí VARCHAR(1) with CHECK constraint
- Purpose: Level fields now indicate which levels exist for each movement (Y/N flags)
- Rationale: All level narratives stored in main `narrative` field; separate flags enable future progressive difficulty selection

**Data Population Scripts:**

1. **update_movement_watch_points_and_visual_cues.sql**
   - Source: Movements_summaries.xlsx (Watch Out Points + Visualisations columns)
   - Watch out points: All 34 movements populated
   - Visual cues: 18 movements populated (16 have no visual cues in source)
   - Multiple columns merged per field (up to 5 watch out point columns, 3 visual cue columns)

2. **update_movement_level_flags.sql**
   - Source: Movements_summaries.xlsx (Levels column)
   - Level 1: 17 movements have L1
   - Level 2: 15 movements have L2
   - Level 3: 5 movements have L3 (One leg stretch, Double leg stretch, Scissors, Leg pull prone, Side bend)
   - Full Version: All 34 movements have FV
   - Special cases: "One level with modifications???" ‚Üí FV only

**Code Changes:**

**Backend:**
- `backend/models/movement.py`:
  - Added `watch_out_points: Optional[str]` field
  - Added 4 level flag fields: `level_1_description`, `level_2_description`, `level_3_description`, `full_version_description`

**Frontend:**
- `frontend/src/store/useStore.ts`:
  - Added `watch_out_points?: string` to Movement interface
  - Added 4 level flag fields with TypeScript comments
- `frontend/src/components/class-playback/ClassPlayback.tsx`:
  - Added `visual_cues?: string` to PlaybackMovement interface
  - Added 4 level flag fields

**Documentation:**
- `database/README_LEVEL_FLAGS_UPDATE.md`:
  - Complete migration guide with execution order
  - Verification queries
  - Data sources and statistics
  - Rollback plan
  - Future enhancements roadmap

**Key Design Decision:**
Level fields repurposed as existence flags rather than storing narratives:
- **Before:** `level_1_description TEXT` (stored narrative)
- **After:** `level_1_description VARCHAR(1)` (stores 'Y' or 'N')
- **Rationale:** Simplifies data model; all narratives in one place; enables easy querying of which levels exist; future option to separate narratives into movement_levels table

**Next Steps (To Execute in Supabase):**
1. ~~Run migration 011 (convert fields to VARCHAR(1))~~ ‚úÖ DONE December 1, 2025
2. ~~Run update_movement_watch_points_and_visual_cues.sql~~ ‚úÖ DONE December 1, 2025
3. ~~Run update_movement_level_flags.sql~~ ‚úÖ DONE December 1, 2025
4. ~~Verify with provided SQL queries~~ ‚úÖ DONE December 1, 2025

---

### Session 12: Jentic Documentation Consolidation & Reorganization ‚úÖ COMPLETE

**Date:** December 2, 2025
**Status:** ‚úÖ Complete - All 6 Tasks Completed Successfully

**Goal:** Create master Jentic documentation with comprehensive index and organized topic areas

**Problem Solved:**
- **8 separate Jentic documentation files** consolidated into single master document
- Eliminated significant duplication across documents
- Converted Q&A format to organized topic areas
- Created comprehensive index for quick navigation

**Why This Mattered:**
1. **Client Relationship**: Clean, professional documentation demonstrates deep Jentic expertise
2. **Educational Goal**: Easier to learn and teach Jentic patterns
3. **Future Projects**: Single source of truth for reusable patterns
4. **Maintainability**: Updates only need to happen in one place

**Completed Work:**

**Task 1: Audit Existing Documentation** ‚úÖ Complete
- ‚úÖ Reviewed all 8 Jentic documentation files
- ‚úÖ Identified duplicate content across documents
- ‚úÖ Mapped content to 10 main topic areas + 40 subsections
- ‚úÖ Noted outdated/redundant content for removal

**Files Audited:**
- `JENTIC_ARCHITECTURE.md`
- `JENTIC_REAL_CODE_ANALYSIS.md`
- `JENTIC_CONCEPTS_EXPLAINED.md`
- `JENTIC_QUICK_REFERENCE.md`
- `JENTIC_ANALYSIS_SUMMARY.md`
- `JENTIC_STANDARDIZATION_AUDIT.md`
- `JENTIC_INTEGRATION_COMPLETE_GUIDE.md`
- `JENTIC_ARCHITECTURE_STYLE_GUIDE.md`

**Task 2: Create Master Index Structure** ‚úÖ Complete
Created `/docs/JENTIC_MASTER.md` with comprehensive table of contents:

- 10 main sections with comprehensive subsections
- Complete anchor link navigation system
- 58 section/subsection headings
- Organized topic hierarchy (no Q&A format)

**Task 3: Consolidate Content by Topic** ‚úÖ Complete
- ‚úÖ Merged duplicate content into single comprehensive sections
- ‚úÖ Converted Q&A format to organized topic areas
- ‚úÖ Added cross-references between related topics
- ‚úÖ Preserved all educational annotations and 40+ code examples
- ‚úÖ Used actual code from codebase (not abstract examples)
- ‚úÖ Created ~3,150 lines of consolidated documentation

**Task 4: Archive Old Documentation** ‚úÖ Complete
- ‚úÖ Moved old files to `/docs/archive/jentic/`
- ‚úÖ Created README in archive explaining consolidation
- ‚úÖ Preserved git history intact

**Task 5: Update References** ‚úÖ Complete
- ‚úÖ Updated CLAUDE.md to reference new JENTIC_MASTER.md
- ‚úÖ Updated all documentation links

**Task 6: Verify Completeness** ‚úÖ Complete
- ‚úÖ All internal anchor links tested and working
- ‚úÖ All 40+ code examples verified accurate
- ‚úÖ All content from 8 original files covered
- ‚úÖ Comprehensive index validated
- ‚úÖ Created verification report: `JENTIC_MASTER_VERIFICATION_REPORT.md`

1. **`/docs/JENTIC_MASTER.md`** - Single source of truth (3,150 lines)
   - 10 main sections with 40+ subsections
   - Complete table of contents with anchor links
   - 40+ accurate code examples (Python, YAML, Bash)
   - 5 ASCII architecture diagrams
   - Quick Start Guide with templates
   - Troubleshooting guide with solutions
   - Complete API reference

2. **`/docs/archive/jentic/README.md`** - Archive documentation
   - Explains consolidation process
   - Maps old files to new sections
   - Usage guidelines

3. **`/docs/JENTIC_MASTER_VERIFICATION_REPORT.md`** - Quality verification
   - Comprehensive verification results
   - Quality metrics (100% across all categories)
   - Coverage analysis
   - Comparison statistics

4. **Updated CLAUDE.md references**
   - All Jentic documentation links point to JENTIC_MASTER.md
   - Old documentation archived

**Results:**
- ‚úÖ **87.5% file reduction** (8 files ‚Üí 1 master document)
- ‚úÖ **24% content reduction** (eliminated duplication: 4,147 ‚Üí 3,150 lines)
- ‚úÖ **100% improved findability** (comprehensive TOC with anchor links)
- ‚úÖ **Single source of truth** established

**Quality Metrics:**
- Completeness: 100% ‚úÖ
- Accuracy: 100% ‚úÖ
- Code Examples: 100% ‚úÖ
- Navigation: 100% ‚úÖ
- Coverage: 100% ‚úÖ

**Success Criteria:** ‚úÖ All Met
- ‚úÖ All 8 old docs consolidated into JENTIC_MASTER.md
- ‚úÖ No duplicate content across documentation
- ‚úÖ Comprehensive index with anchor links (58 sections)
- ‚úÖ All content organized by topic (not Q&A format)
- ‚úÖ Code examples from actual project (not abstract)
- ‚úÖ Old files archived with explanation
- ‚úÖ User can find any Jentic topic in <30 seconds

**Commits:**
- `33aab2b`: Sections 1-3 complete
- `125959b`: Sections 4-5 complete
- `7b8e03c`: Sections 6-10 complete (100%)
- `bb7828f`: Archive old documentation
- `e93e086`: Verification report complete

---

### Session 13: Advanced Delivery Modes - Phase 3 ‚è∏Ô∏è DEFERRED

**Goal:** Multi-modal delivery (audio narration + visual demonstrations)

**Status:** ‚è∏Ô∏è Plans documented, deferred pending more testing of core features

**Context:**
Users may want:
- **Text narrative** (current, Phase 1)
- **Audio narration** (TTS, Phase 3)
- **Visual demonstration** (video/images, Phase 3)

Phase 3 deferred to focus on core architecture first.

#### 1. Audio Narrative Generation

**Integration Options:**
- **ElevenLabs** - High-quality, natural voices
- **OpenAI TTS** - Cost-effective, good quality
- **Google Cloud TTS** - Enterprise option

**Implementation:**
```python
# Generate audio for each class section
async def generate_audio_narrative(section_text: str) -> str:
    """
    Returns audio_url for the narrated text
    Caches generated audio for reuse
    """
    audio_url = await tts_service.synthesize(
        text=section_text,
        voice="calm_female",  # Pilates instructor voice
        speed=0.9  # Slightly slower for instruction
    )
    return audio_url
```

**Database Changes:**
```sql
-- Add audio URLs to all content tables
ALTER TABLE movements ADD COLUMN audio_url TEXT;
ALTER TABLE preparation_scripts ADD COLUMN audio_url TEXT;
ALTER TABLE warmup_routines ADD COLUMN audio_url TEXT;
-- etc.
```

#### 2. Visual Demonstrations

**Content Types:**
- **Still images** - Key positions for each movement
- **Video clips** - Full movement demonstrations
- **Animations** - Loop-able movement cycles

**Database Changes:**
```sql
ALTER TABLE movement_levels ADD COLUMN video_url TEXT;
ALTER TABLE movement_levels ADD COLUMN thumbnail_url TEXT;
ALTER TABLE movement_levels ADD COLUMN key_position_images JSONB;
-- JSONB format: [{"position": "start", "url": "..."}, {"position": "mid", "url": "..."}, ...]
```

**Frontend Changes:**
```typescript
// ClassPlayback component enhancement
interface DeliveryMode {
  text: boolean;
  audio: boolean;
  visual: boolean;
}

// User can toggle:
// - Text only (current)
// - Text + Audio
// - Text + Visual
// - All three (full multi-modal)
```

#### 3. User Preferences for Delivery

```sql
-- Extend user_preferences table
ALTER TABLE user_preferences
  ADD COLUMN delivery_format_text BOOLEAN DEFAULT true,
  ADD COLUMN delivery_format_audio BOOLEAN DEFAULT false,
  ADD COLUMN delivery_format_visual BOOLEAN DEFAULT false;
```

**Progressive Enhancement Strategy:**
- Default: Text (works for everyone)
- Opt-in: Audio (requires TTS service)
- Opt-in: Visual (requires video content)
- All devices support text; audio/visual enhance experience

#### 4. Performance Considerations

**Audio:**
- Pre-generate and cache common narratives
- Use CDN for audio file delivery
- Stream audio with HTML5 `<audio>` element

**Video:**
- Use adaptive bitrate streaming (HLS/DASH)
- Provide quality options (480p, 720p, 1080p)
- Cache video thumbnails aggressively
- Consider YouTube/Vimeo hosting vs self-hosted

**Cost Management:**
- TTS: ~$15/1M characters (OpenAI pricing)
- Video hosting: ~$0.01/GB delivery (Cloudflare Stream)
- Budget based on user base and usage patterns

---

**Next Sessions Preview:**

- **Session 11.75:** Movement Data Population ‚úÖ COMPLETED (SQL executed December 1, 2025)
- **Session 12:** Jentic Documentation Consolidation ‚úÖ COMPLETED (December 2, 2025)
- **Session 13:** Advanced Delivery Modes ‚è∏Ô∏è DEFERRED (pending more testing)
- **Session 14:** EU AI Act Compliance Dashboard & Testing
- **Session 15:** ### Role
You are a compliance specialist with expertise in EU AI Act requirements.

### Context
Day 13. Core app functional. Implement compliance dashboard for AI decision transparency.

### Your Task
Build compliance dashboard for EU AI Act requirements.

### What You Should Do

**Step 1: Decision Transparency View**
- Display all AI agent decisions for user
- Show input parameters and outputs
- Explain reasoning for each decision
- Confidence scores

**Step 2: Bias Monitoring Dashboard**
- Track model drift over time
- Display fairness metrics
- Alert on bias detection
- Historical comparison charts

**Step 3: Audit Trail Interface**
- Complete decision history
- Export functionality (CSV, JSON)
- Filter by date, agent type, user
- Search capabilities

**Step 4: Research Source Tracking**
- Display MCP research sources
- Source attribution for all web content
- Quality scores
- Trust indicators

**Step 5: AI Compliance System End-to-End Testing (Deferred from Session 8)**
- **Context**: Compliance infrastructure built in Session 8, but testing deferred until AI behaviors are active
- **Prerequisites**: Session 11 (OpenAI GPT Integration) must be complete - AI agents actively making decisions
- **What to Test**:
  - AI decision logging with real AI operations
    - Verify all agent decisions logged to `ai_decision_log` table
    - Check input parameters, outputs, reasoning, confidence scores
    - Test with sequence, music, and meditation agents
  - Bias monitoring with actual model outputs
    - Run model drift detection scripts
    - Verify fairness metrics tracking
    - Test alert system for bias detection
  - Model drift detection with real data
    - Check historical comparison charts
    - Verify drift threshold alerts working
    - Test with varied input patterns
  - GDPR data export functionality
    - Test `/api/compliance/my-data` endpoint with valid JWT
    - Verify all user compliance data exported correctly
    - Test ROPA audit log access
    - Verify AI decision history export
- **Known Issue to Fix**: GDPR Article 15 data download (HTTP 500 error)
  - Check Render backend logs for error details
  - Verify Row-Level Security (RLS) policies on compliance tables
  - Test endpoint authentication flow
  - Fix PIILogger.log_data_export() if needed
- **Integration Testing**:
  - Generate 10 test classes with AI
  - Verify each class generation logged
  - Check bias metrics after generation
  - Export compliance data and verify completeness

### Expected Outputs
- Compliance dashboard page
- Agent decision log viewer
- Bias monitoring charts
- Export functionality
- Source attribution display
- **AI compliance testing report** (new)
- **GDPR data export fix** (addresses Session 8 known issue)

### Success Criteria
- [ ] All AI decisions logged and visible
- [ ] Bias monitoring operational
- [ ] Export works correctly
- [ ] Source attribution complete
- [ ] EU AI Act compliant
- [ ] AI compliance system tested end-to-end with real AI operations
- [ ] GDPR Article 15 data download working (500 error fixed)


### Role
You are a QA engineer specializing in React and FastAPI testing.

### Context
Day 12. Features complete including LLM integration. Now comprehensive testing.

### Your Task
Create complete test suite for frontend and backend.

### What You Should Do
- Unit tests (Jest/Pytest)
- Integration tests
- E2E tests (Playwright)
- MCP mock server
- Performance tests

### Expected Coverage
- Backend: >80%
- Frontend: >70%
- Critical paths: 100%

## **SESSION 14: Mobile Responsiveness**

### Role
You are a mobile-first UI developer.

### Context
Day 15. Desktop complete. Optimize for mobile.

### Your Task
Ensure complete mobile responsiveness.

### What You Should Do
- Touch-optimized drag-and-drop
- Mobile navigation
- Responsive charts
- Mobile-specific layouts
- PWA features
---
## **SESSION 15: Performance Optimization & OpenAI/MCP Enhancements**

### Role
You are a full-stack developer with expertise in MCP integration and caching strategies.

### Context
Day 11. LLM integration complete. Now implement MCP advanced features for web research.

### Your Task
Implement MCP research capabilities with caching, quality scoring, and batch operations.

### What You Should Do

**Step 1: Implement Caching Layer**
```python
class MCPCache:
    def __init__(self, redis_client, ttl_hours=24):
        self.redis = redis_client
        self.ttl = ttl_hours * 3600

    async def get_or_fetch(self, query: str, fetcher):
        cache_key = f"mcp:{hashlib.md5(query).hexdigest()}"
        cached = await self.redis.get(cache_key)

        if cached:
            return json.loads(cached)

        result = await fetcher(query)
        await self.redis.setex(cache_key, self.ttl, json.dumps(result))
        return result
```

**Step 2: Quality Scoring System**
```python
class ResearchQualityScorer:
    TRUSTED_DOMAINS = [
        'pilatesmethod.com',
        'pilatesfoundation.com',
        'balancedbody.com',
        'ncbi.nlm.nih.gov'
    ]

    def score_source(self, url: str, content: str) -> float:
        # Score based on domain authority
        # Check for citations
        # Verify author credentials
        # Check recency
        return score
```

**Step 3: Batch Research Operations**
- Research multiple movements in parallel
- Organize batch results
- Progress tracking

**Step 4: Research Scheduling**
- Weekly automatic updates
- Popular movement research
- Stale data detection

### Expected Outputs
- MCP caching implementation
- Quality scoring system
- Batch research API
- Automated scheduler
- Research analytics

### Success Criteria
- [ ] MCP caching reduces duplicate requests by >70%
- [ ] Quality scoring filters low-quality sources
- [ ] Batch operations work efficiently
- [ ] Research results properly attributed
- [ ] Scheduler runs automatically
### Role
You are a performance engineer and integration specialist.

### Context
Day 16. Features complete. Optimize performance and address Session 11.5 backlog items.

### Your Task
Optimize frontend and backend performance, add MCP Playwright integration, and implement OpenAI Redis caching.

### What You Should Do

**Performance Optimization:**
- Code splitting
- Lazy loading
- Database query optimization
- Caching strategies (Redis setup)
- CDN setup
- Bundle size reduction

## **SESSION 16: Class Builder modal bug**

Class builder modal screen is buggy. Unclear on memory over details but it should be reviewed in due course.

---

## üìö FUTURE PLANS

### Additional Potential Enhancements

**Note:** Session 12 (Jentic Documentation Consolidation) has been **completed** (December 2, 2025).

Future considerations:
- Additional music tracks from Internet Archive collections
- Playlist editing/customization for users
- Music volume controls in playback UI
- Music fade in/out between movements
- Multi-modal delivery (TTS + video demonstrations)
- MCP Playwright caching and quality scoring
- Comprehensive E2E testing suite
- Mobile responsiveness and PWA features
